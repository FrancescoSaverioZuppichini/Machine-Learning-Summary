\relax 
\abx@aux@sortscheme{nty}
\abx@aux@refcontext{nty/global/}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}History of Machine Learning}{1}}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Write something about the history of ML}{1}}
\pgfsyspdfmark {pgfid1}{20112834}{32743046}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Gradient Descend}{1}}
\newlabel{eq: gradient_descent}{{1}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Loss Functions}{1}}
\newlabel{eq: MSE}{{2}{1}}
\newlabel{eq: soft_max}{{3}{1}}
\newlabel{eq: log_like}{{4}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Perceptron}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Definition}{2}}
\newlabel{eq: perceptron}{{5}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Neural Network}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Forward pass}{2}}
\newlabel{eq:forward_pass}{{7}{2}}
\newlabel{eq:forward_pass_vectorized}{{8}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Delta rules}{3}}
\newlabel{eq: deltaRule_1}{{9}{3}}
\newlabel{eq:deltaRule_2}{{10}{3}}
\newlabel{eq:deltaRule}{{11}{3}}
\newlabel{eq: delta_on_delta}{{12}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Back Propagation}{3}}
\newlabel{eq: back_propagation}{{14}{3}}
\newlabel{eq: back_propagation_bias}{{15}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Convolutional Neural Network}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: cnn}{{1}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Notation}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Convolutional Layer}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax }}{5}}
\newlabel{fig: pool}{{2}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax }}{5}}
\newlabel{fig: cnn_faces}{{3}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Recurrent Neural Network}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Definition}{6}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Fold and Unfold representation of a RNN\relax }}{6}}
\newlabel{fig: RNN}{{4}{6}}
\newlabel{eq: output_rnn}{{16}{6}}
\newlabel{eq: output_rnn_vectorised}{{17}{6}}
\newlabel{eq: activation_rnn}{{18}{6}}
\newlabel{eq: rnn_weigt_update}{{19}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Loss}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Vanishing Gradient Problem}{7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sigmoid and its derivative over time\relax }}{7}}
\newlabel{fig: sigmoid_over_time}{{5}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Long Short Term Memory}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Definition}{7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An unrolled LSTM\relax }}{7}}
\newlabel{fig: unrolled_LSTM}{{6}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {8}Support Vector Machine}{8}}
\newlabel{eq: decision_surface}{{20}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Linear separable data}{9}}
\newlabel{eq: decision_surface_linear}{{21}{9}}
\newlabel{eq: optimal_hyperplane}{{22}{9}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Support Vectors\relax }}{9}}
\newlabel{fig: support_vector}{{7}{9}}
\newlabel{eq: discriminant}{{23}{9}}
\newlabel{eq: margin}{{24}{9}}
\newlabel{eq: hard_margin}{{25}{10}}
\newlabel{eq: softMargin}{{26}{10}}
\newlabel{eq: optimal_weight_lagrande}{{27}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Non linear separable data}{10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Mapping in a SVM\relax }}{10}}
\newlabel{fig: SVM}{{8}{10}}
\newlabel{eq: feature_map}{{28}{10}}
\newlabel{eq: optimal_hyperplane_feature}{{30}{11}}
\newlabel{eq: kernel}{{31}{11}}
\newlabel{eq: optimal_hyperplane_feature}{{32}{11}}
\newlabel{eq: dual_problem_kernel}{{33}{11}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Kernel Trick from 2d to 3d\relax }}{12}}
\newlabel{fig: kernel_trick}{{9}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {9}Deep Learning}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Supervised Learning}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Reinforcement Learning}{12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Reinforcement Learning Flow\relax }}{12}}
\newlabel{fig: reinforcement_flow}{{10}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Unsupervised Learning}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Training Techniques}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.4.1}Mini-batch}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}Regularisation}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.5.1}L1 Regularisation}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.5.2}Dropout Regularisation}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.6}Activations Functions}{13}}
