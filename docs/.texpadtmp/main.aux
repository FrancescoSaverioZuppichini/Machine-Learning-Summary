\relax 
\abx@aux@sortscheme{nty}
\abx@aux@refcontext{nty/global/}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}History of Machine Learning}{1}}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Write something about the history of ML}{1}}
\pgfsyspdfmark {pgfid1}{20112834}{32713409}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Gradient Descend}{1}}
\newlabel{eq: gradient_descent}{{1}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Perceptron}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Definition}{1}}
\newlabel{eq: perceptron}{{2}{1}}
\newlabel{eq: MSE_perceptron}{{3}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Neural Network}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Forward pass}{2}}
\newlabel{eq:forward_pass}{{5}{2}}
\newlabel{eq:forward_pass_vectorized}{{6}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Delta rules}{2}}
\newlabel{eq: deltaRule_1}{{7}{2}}
\newlabel{eq:deltaRule_2}{{8}{2}}
\newlabel{eq:deltaRule}{{9}{2}}
\newlabel{eq: delta_on_delta}{{10}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Back Propagation}{3}}
\newlabel{eq: back_propagation}{{12}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Convolutional Neural Network}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: cnn}{{\caption@xref {fig: cnn}{ on input line 110}}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Notation}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Convolutional Layer}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Recurrent Neural Network}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Definition}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Fold and Unfold representation of a RNN\relax }}{4}}
\newlabel{fig: RNN}{{1}{4}}
\newlabel{eq: output_rnn}{{13}{4}}
\newlabel{eq: activation_rnn}{{14}{4}}
\newlabel{eq: rnn_weigt_update}{{15}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Loss}{5}}
\newlabel{eq: cross_entropy}{{16}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Vanishing Gradient Problem}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Sigmoid and its derivative over time\relax }}{5}}
\newlabel{fig: sigmoid_over_time}{{2}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {8}Long Short Term Memory}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Definition}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An unrolled LSTM\relax }}{6}}
\newlabel{fig: unrolled_LSTM}{{3}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {9}Support Vector Machine}{7}}
\newlabel{eq: decision_surface}{{17}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Linear separable data}{7}}
\newlabel{eq: decision_surface_linear}{{18}{7}}
\newlabel{eq: optimal_hyperplane}{{19}{7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Support Vectors\relax }}{7}}
\newlabel{fig: support_vector}{{4}{7}}
\newlabel{eq: discriminant}{{20}{8}}
\newlabel{eq: margin}{{21}{8}}
\newlabel{eq: hard_margin}{{22}{8}}
\newlabel{eq: softMargin}{{23}{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Non linear separable data}{8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Mapping in a SVM\relax }}{8}}
\newlabel{fig: SVM}{{5}{8}}
\newlabel{eq: feature_map}{{24}{8}}
\newlabel{eq: optimal_hyperplane_feature}{{26}{8}}
\newlabel{eq: kernel}{{27}{9}}
\newlabel{eq: optimal_hyperplane_feature}{{28}{9}}
\newlabel{eq: dual_problem_kernel}{{29}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {10}Deep Learning}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Supervised Learning}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Reinforcement Learning}{9}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Reinforcement Learning Flow\relax }}{10}}
\newlabel{fig: reinforcement_flow}{{6}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Unsupervised Learning}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Training Techniques}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.4.1}Mini-batch}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {10.5}Regularisation}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.1}L1 Regularisation}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.2}Dropout Regularisation}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {10.6}Activations Functions}{10}}
